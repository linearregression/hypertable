#summary Load Balancing Design
<wiki:toc/>

= Introduction =

The purpose of load balancing is to spread load across the range servers to maximize overall performance and availability.  

= Balancer Mechanics =

The Master will include a load balancer.  It will come in the form of a class that is abstracted so that alternate balancers can be easily added.  This !LoadBalancer class will have a `balance()` method that gets called by the Master maintenance task which runs periodically (default = 30 seconds).  If new range servers are added or the load variance among existing servers gets too large, it will commence a balance operation.

== Balance Operation ==

The balance operation will consist of the following steps:

  # The !LoadBalancer will set a flag indicating that a balance operation is progress.  This will prevent the balancer from commencing another balance operation while another one is in progress.
  # A BALANCE_START MML (Master Meta Log) entry will get written that includes all of the information necessary to carry out the rebalance operation (e.g. which ranges are being moved to which servers).
  # The asynchronous `RangeServer::relinquish_range()` method will be called for each range being moved in the balance operation.
  # When each range is relinquished, the master will be notified via it's `Master::move_range()` method which will consult the balancer to determine which server it is assigned to.  Once it knows which server it is assigned to, it will write a RANGE_MOVE_START MML entry (with info about the assigned range server) and respond success to the relinquishing range server.  Then it will invoke the `RangeServer::load_range()` operation.  Upon successful completion it will write a RANGE_MOVE_LOADED MML entry and inform the balancer that the range has been loaded.
  # When the !RangeServer writes the SPLIT_DONE or RELINQUISH_DONE entry in it's log, it will invoke the `Master::relinquish_acknowledge()` method of the Master which will write a RANGE_MOVE_ACKNOWLEDGED entry in the MML and inform the !LoadBalancer that the range move has been acknowledged.  Un-acknowledged ranges will be excluded from future balance operations.   
  # Once the last range has been loaded, the balancer will write a BALANCE_COMPLETE MML entry, unset the bit indicating that a balance is in progress, and continue normal operation.

== Master Failover ==

When the Master fails over during a balance operation, it will recover its state with the following steps.

  # Master will re-play the MML and will initialize the !LoadBalancer with unclosed BALANCE_START information as well as any ranges which are not part of the in-progress balance operation but are in the RANGE_MOVE_START or unacknowledged RANGE_MOVE_LOADED state.
  # !LoadBalancer will record unacknowledged RANGE_MOVE_LOADED ranges in an exclude map to prevent them from being considered for subsequent balance operations
  # !LoadBalancer will signal to decrease the maintenance interval to 1 second
  # As soon as each participating range server re-connects, the !LoadBalancer will handle each range as follows: 
    * For ranges not yet RANGE_MOVE_START state, it will invoke `RangeServer::relinquish_range()`  If this returns RANGE_NOT_FOUND, it will assume the move operation was completed for this range
    * For those ranges in the RANGE_MOVE_START state it will create a !MoveRange task and enqueue it onto the Master's application queue.
  # Once all of the necessary servers have re-connected the !LoadBalancer will signal to increase the maintenance interval back to its normal value

== !RangeServer Failure ==

If a range server participating in a balance operation fails and a recovery operation commences for that range server, the !LoadBalancer will be notified and will handle uncompleted ranges as follows:

  * For ranges not yet in the RANGE_MOVE_START state, it will assume the move operation was completed for this range and mark it completed.
  * For those ranges in the RANGE_MOVE_START state it will consult the recovery process to determine if the range was loaded or not.  If the range was loaded, it will write a RANGE_MOVE_LOADED MML entry for the range.  Otherwise, it will assign the range a new location and write a RANGE_MOVE_RESTARTED MML entry with the old location and the new one.  This will effectively be the same state as RANGE_MOVE_STARTED with the new location.  It will then create a !MoveRange task and enqueue it onto the Master's application queue.

= Balancer Input =

== `sys/RS_STATS` Table ==

This will be a system table used to track load statistics for servers and ranges.  Load statistics will be computed and stored hourly.  To minimize the amount of data kept in this table, 24 samples will be kept for each range and 7*24 (one week) samples will be kept for each range server.  This will be achieved with the MAX_VERSIONS option of the column specifications.  The reason we use MAX_VERSIONS instead of TTL is so that when a system is shut down for long periods of time, it can be brought back up again and still have load data to work with.  The table will have the following row key format:
{{{
<server-id>[:<table-id>]
}}}
One problem to consider when deciding on a row key format is row overflow.  Let's assume that the system is managing a single very large table, each range server has 10,000 ranges, and the row key and value data for each sample is 1000.  With 24 samples, this puts each row in the RS_STATS table at about 10000*1000*24, or 240MB.  This is less than the 256MB max range size and considerably less with compression factored in.  The `RS_STATS` table will have the following schema:
{{{
create table RS_STATS (
  server,
  range,
  range_start_row,
  range_split,
  ACCESS GROUP server ( server ),
  ACCESS GROUP range ( range, range_start_row, range_split )
);
}}}

The columns in the range access group will have a qualifier that represents the end row of the range. 

*!RangeServer failure*

System ranges (e.g. METADATA, RS_STATS, etc.) will need to be recovered first.  The Master will maintain range server load information and will use that information to select lightly loaded servers to move the system ranges to.  If it does not have this information (e.g. the Master was recently restarted), it will randomly assign the system ranges.  The balancing operation cannot proceed until all of the system ranges have been recovered.

== Monitoring Data ==

Every 30 seconds the Master gathers monitoring statistics from all !RangeServers.  This data consists of data aggregated per-table and overall server and system statistics.  This data does not contain any per-range statistics, but includes useful capacity information like amount of physical RAM, number of CPUs, and disk capacity and usage.

= Load Balancer Class Definition =

The following is pseudo-code for the !LoadBalancer base class.
{{{
class LoadBalancer {
  public:
    LoadBalancer(vector<RangeState> &range_states) = 0;
    LoadBalancer(vector<RangeState> &range_states, BalanceOperation &operation) = 0;
    void balance() = 0;
    String assign_to_server(TableIdentifier &tid, RangeIdentifier &rid) = 0;
    void range_move_loaded(TableIdentifier &tid, RangeIdentifier &rid) = 0;
    void range_relinquish_acknowledged(TableIdentifier &tid, RangeIdentifier &rid) = 0;
    time_t maintenance_interval() = 0;
};
}}}

= Basic Balancing Algorithm =

The Basic balancer will attempt to optimize for both load balance as well as even distribution of ranges for each table across the range servers.  There are three situations that will prompt a balancing operation.  The following sections describe these situations and the policy for triggering a balance operation.

== Load Imbalance ==

Balance operations for load imbalances will happen once per day.  The balancer will initialize itself by scanning the weekly server load data to determine the best time of day to perform a balance operation and will schedule a balance operation for that time.  When the time arrives, it will consider performing a balance using server load data for the previous 24 hours only.  It will scan the RS_STATS table to build a map of server load average (load map) for the past 24 hours and use this information along with a configured load variance threshold to determine if a balance operation is necessary.  Whenever a server or servers are added, it will wait for at least 24 hours before doing a "load imbalance" balance operation to give the servers time to build up a day's worth of load statistics.  The load variance threshold will be set at a large enough value to account for variance due to range split operations.  If a balance operation is necessary, the algorithm describe below will be used to come up with a balance plan.

== !RangeServer Added ==

Whenever a new range server or range servers are added to the system, the balancer will immediately schedule a balance operation to move ranges from the existing servers to the newly added servers.  The RS_STATS table will be scanned to build a map of server load average (load map) for the past 24 hours.  The load map will be fed into the balance algorithm described blow to come up with a balance plan.

== Range Split ==

When the `Master::move_range()` method is invoked due to a range split operation, the balancer will assign it to a new range server.  Since split operations can happen frequently throughout the day and have the effect of throwing off the load average statistics, a simpler approach will be used to assign the range to a server by solely optimizing for even range distribution for the table being split.  The balancer will use the monitoring information it receives on a regular basis to build up a range count map for the table being split.  This map will contain range count information for each range server in the system.  The server containing the smallest number of ranges for the table being split will be chosen to receive the range.

== The Basic Algorithm ==


For balancing load, the system will compute a single metric for load based on some combination of the following statistics:

  * scans/s
  * updates/s
  * cells read/s
  * cells written/s
  * bytes read/s
  * bytes written/s




The basic balancer will use range server load average to determine whether or not balancing is necessary.  It will also consider disk usage statistics (if available) to prevent any system from filling its disks beyond a configured threshold (e.g. 90%).  When the balancer starts, it will open a scanner on the RS_STATS table and scan it to build a per-server load statistics map.

Ranges that have moved in the past week due to a balancing operation will not be considered.