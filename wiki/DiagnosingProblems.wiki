#summary Steps to take when Hypertable goes down
<wiki:toc/>

== Step 1. Check Hypertable Processes ==

Start with the *DFS broker*:
{{{
cap> ps auxww | fgrep -i broker | fgrep -v grep | fgrep -v cronolog | fgrep -v "start-dfs"
 ** [out :: motherlode013] zvents   29391  1.5  2.7 1442524 448072 ?      Sl   Nov21 106:14 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode011] zvents   16877  1.1  2.8 1508768 471812 ?      Sl   Nov21  79:22 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode014] zvents    4808  1.7  2.5 1510864 416016 ?      Sl   Nov21 119:26 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode017] zvents   17545  1.7  2.0 1516016 343556 ?      Sl   Nov21 117:17 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode019] zvents   19674  1.9  2.1 1524428 348276 ?      Sl   Nov21 133:09 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode016] zvents   22543  2.1  2.3 1523984 381052 ?      Sl   Nov21 141:43 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode015] zvents   26823  1.6  2.1 1519576 355668 ?      Sl   Nov21 112:26 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode010] zvents   27273  1.3  2.0 1449532 334240 ?      Sl   Nov21  88:45 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode012] zvents   30954 43.4  1.8 1500672 311268 ?      Sl   Nov21 2902:23 java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n -classpath /opt/hypertable/0.9.0.12:/opt/hypertable/0.9.0.12/lib/*.jar:/opt/hypertable/0.9.0.12/java/lib/commons-logging-1.0.4.jar:/opt/hypertable/0.9.0.12/java/lib/hadoop-0.18.2-core.jar:/opt/hypertable/0.9.0.12/java/lib/hypertable-0.9.0.12.jar:/opt/hypertable/0.9.0.12/java/lib/junit-4.3.1.jar:/opt/hypertable/0.9.0.12/java/lib/log4j-1.2.13.jar:/opt/hypertable/0.9.0.12/lib/jetty-ext/*.jar org.hypertable.DfsBroker.hadoop.main --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
}}}

Then check for the *range servers*:
{{{
cap> cd /tmp; ps auxww | fgrep RangeServer | fgrep -v grep | fgrep -v cronolog
 ** [out :: motherlode013] zvents   29475 13.7 23.9 4424544 3934624 ?     Sl   Nov21 917:34 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode016] zvents   22627 16.2 30.8 5562500 5073716 ?     Sl   Nov21 1084:32 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode017] zvents   17631 12.6 27.4 4927584 4516956 ?     Sl   Nov21 845:19 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode011] zvents   16961  9.8 20.7 3756304 3406432 ?     Sl   Nov21 657:37 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode012] zvents   31038 22.2 65.1 19567820 10700568 ?   Sl   Nov21 1488:24 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode019] zvents   19758 16.1 27.5 4913872 4522696 ?     Sl   Nov21 1077:11 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode014] zvents    4892 15.6 27.2 4863100 4473520 ?     Sl   Nov21 1044:41 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode010] zvents   27522  9.6 21.0 4053916 3464136 ?     Sl   Nov21 648:04 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode015] zvents   26907 12.7 27.8 5038916 4570380 ?     Sl   Nov21 854:01 /opt/hypertable/0.9.0.12/bin/Hypertable.RangeServer --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.RangeServer.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
}}}

Then check for the *Hypertable* and *Hyperspace master* processes:
{{{
cap> cd /tmp; ps auxww | fgrep Master | fgrep -v grep | fgrep -v cronolog
 ** [out :: motherlode010] zvents   27358  0.0  0.1 314044 19432 ?        Sl   Nov21   2:18 /opt/hypertable/0.9.0.12/bin/Hyperspace.Master --pidfile=/opt/hypertable/0.9.0.12/run/Hyperspace.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
 ** [out :: motherlode010] zvents   27412  0.0  0.0 329404 13656 ?        Sl   Nov21   0:05 /opt/hypertable/0.9.0.12/bin/Hypertable.Master --pidfile=/opt/hypertable/0.9.0.12/run/Hypertable.Master.pid --verbose --config=/opt/hypertable/0.9.0.12/conf/production-hypertable.cfg
error: command "cd /tmp; ps auxww | fgrep Master | fgrep -v grep | fgrep -v cronolog" failed on motherlode011,motherlode012,motherlode013,motherlode014,motherlode015,motherlode016,motherlode017,motherlode019
}}}

== Step 2: Inspect System Log ==

On our system (CentOS 5) this is in /var/log/messages.  It should be inspected on all machines and you should look out for things like processes that were killed because they ran out of memory.  For example, here's a snippet from the system log on one of our machines that had a problem.  Notice the "java invoked oom-killer".

{{{
Nov 21 11:29:10 motherlode013 kernel: Swap cache: add 7079047, delete 7078792, find 2157462/2384265, race 0+179
Nov 21 11:29:10 motherlode013 kernel: Free swap  = 0kB
Nov 21 11:29:11 motherlode013 kernel: Total swap = 8385856kB
Nov 21 11:29:11 motherlode013 kernel: Free swap:            0kB
Nov 21 11:29:11 motherlode013 kernel: 4456448 pages of RAM
Nov 21 11:29:11 motherlode013 kernel: 348373 reserved pages
Nov 21 11:29:11 motherlode013 kernel: 14473 pages shared
Nov 21 11:29:11 motherlode013 kernel: 257 pages swap cached
Nov 21 11:29:12 motherlode013 kernel: java invoked oom-killer: gfp_mask=0x201d2, order=0, oomkilladj=0
Nov 21 11:29:12 motherlode013 kernel: 
Nov 21 11:29:12 motherlode013 kernel: Call Trace:
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff800bed05>] out_of_memory+0x8e/0x2f5
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff8000f071>] __alloc_pages+0x22b/0x2b4
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff80012720>] __do_page_cache_readahead+0x95/0x1d9
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff8003d03b>] lock_timer_base+0x1b/0x3c
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff800352ff>] find_extend_vma+0x16/0x59
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff800130ab>] filemap_nopage+0x148/0x322
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff800087ed>] __handle_mm_fault+0x1f8/0xdf4
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff80064a6a>] do_page_fault+0x4b8/0x81d
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff8009b446>] autoremove_wake_function+0x0/0x2e
Nov 21 11:29:12 motherlode013 kernel:  [<ffffffff8005bde9>] error_exit+0x0/0x84
Nov 21 11:29:12 motherlode013 kernel: 
}}}

== Step 3: Check Disk Usage on All Machines ==

For example:

{{{
[doug@motherlode010 clusterB]$ cap shell
  * executing 'shell'
====================================================================
Welcome to the interactive Capistrano shell! This is an experimental
feature, and is liable to change in future releases. Type 'help' for
a summary of how to use the shell.
--------------------------------------------------------------------
cap> df
[establishing connection(s) to motherlode010, motherlode011, motherlode012, motherlode013, motherlode014, motherlode015, motherlode016, motherlode017, motherlode019]
 ** [out :: motherlode013] Filesystem           1K-blocks      Used Available Use% Mounted on
 ** [out :: motherlode013] /dev/md1              59522644  15510252  40940008  28% /
 ** [out :: motherlode013] /dev/sdd5            687649580  22251900 629903272   4% /data4
 ** [out :: motherlode013] /dev/sdc5            687649580  22905696 629249476   4% /data3
 ** [out :: motherlode013] /dev/sdb5            687649580  21882712 630272460   4% /data2
 ** [out :: motherlode013] /dev/sda7            685554676  69937104 580231600  11% /data1
 ** [out :: motherlode013] /dev/md0                101018     11580     84222  13% /boot
 ** [out :: motherlode013] tmpfs                  8216148         0   8216148   0% /dev/shm
 ** [out :: motherlode013] netapp-a:/vol/vol1/common
 ** [out :: motherlode013] 770623808 525759488 244864320  69% /common
 ** [out :: motherlode013] netapp-b.admin.zvents.com:/vol/vol0/home/zvents
 ** [out :: motherlode013] 90390400  47017280  43373120  53% /home/zvents
 ** [out :: motherlode013] netapp-b.admin.zvents.com:/vol/vol0/home/doug
 ** [out :: motherlode013] 90390400  47017280  43373120  53% /home/doug
 ** [out :: motherlode012] Filesystem           1K-blocks      Used Available Use% Mounted on
 ** [out :: motherlode012] /dev/md1              59522644  56458664         0 100% /
 ** [out :: motherlode012] /dev/sdd5            687649580  22523020 629632152   4% /data4
 ** [out :: motherlode012] /dev/sdc5            687649580  21937116 630218056   4% /data3
 ** [out :: motherlode012] /dev/sdb5            687649580  21504128 630651044   4% /data2
 ** [out :: motherlode012] /dev/sda7            685554676  70094352 580074352  11% /data1
 ** [out :: motherlode012] /dev/md0                101018     11580     84222  13% /boot
 ** [out :: motherlode012] tmpfs                  8216148         0   8216148   0% /dev/shm
 ** [out :: motherlode012] netapp-a:/vol/vol1/common
 ** [out :: motherlode012] 770623808 525759488 244864320  69% /common
 ** [out :: motherlode012] netapp-b.admin.zvents.com:/vol/vol0/home/zvents
 ** [out :: motherlode012] 90390400  47017280  43373120  53% /home/zvents
 ** [out :: motherlode012] netapp-b.admin.zvents.com:/vol/vol0/home/dranch
 ** [out :: motherlode012] 90390400  47017280  43373120  53% /home/dranch
 ** [out :: motherlode012] netapp-b.admin.zvents.com:/vol/vol0/home/doug
 ** [out :: motherlode012] 90390400  47017280  43373120  53% /home/doug
[...]
}}}

== Step 4: Inspect Hypertable Logs ==

On each machine, you can run the following command:

{{{
[doug@motherlode011 0.9.0.12]$ find /opt/hypertable/0.9.0.12/log/archive -name '*.log' -print -exec fgrep ERROR {} \; | more
/opt/hypertable/0.9.0.12/log/archive/2008-11/23/Hypertable.RangeServer.log
1227427200 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427203 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427206 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427209 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427212 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427215 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427218 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427221 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427224 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
1227427227 ERROR Hypertable.RangeServer : (/usr/src/hypertable/src/cc/Hypertable/RangeServer/RangeServer.cc:671) RANGE SERVER range not found '(a) pageviews_per
_day[venue_878255..venue_973606]'
}}}

== Step 5: Inspect the DFS ==

Here's how you do it on our production cluster (running HDFS).  First make sure the following processes are running on the master node:

{{{
org.apache.hadoop.dfs.NameNode
org.apache.hadoop.dfs.DataNode
org.apache.hadoop.dfs.SecondaryNameNode
org.apache.hadoop.mapred.JobTracker
org.apache.hadoop.mapred.TaskTracker
}}}

Then on each of the slave nodes, ensure the following two java processes are running:

{{{
org.apache.hadoop.dfs.DataNode
org.apache.hadoop.mapred.TaskTracker
}}}

Then on any machine that looks like it is having problems, check the HDFS log files for exceptions:

{{{
cd /opt/hadoop/current/logs/
[doug@motherlode010 logs]$ fgrep -i exception *.log | more
hadoop-zvents-datanode-motherlode010.admin.zvents.com.log:2008-12-01 00:28:26,420 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(10.0.30.213:50010, st
orageID=DS-393702405-10.0.30.213-50010-1222839388069, infoPort=50075, ipcPort=50020):Got exception while serving blk_8389698773741314860_195578 to /10.0.30.213:
hadoop-zvents-datanode-motherlode010.admin.zvents.com.log:java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write.
 ch : java.nio.channels.SocketChannel[connected local=/10.0.30.213:50010 remote=/10.0.30.213:60792]
hadoop-zvents-datanode-motherlode010.admin.zvents.com.log:2008-12-01 00:28:26,420 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(10.0.30.213:50010, s
torageID=DS-393702405-10.0.30.213-50010-1222839388069, infoPort=50075, ipcPort=50020):DataXceiver: java.net.SocketTimeoutException: 480000 millis timeout while w
aiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/10.0.30.213:50010 remote=/10.0.30.213:60792]
hadoop-zvents-datanode-motherlode010.admin.zvents.com.log:2008-12-01 00:28:26,968 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(10.0.30.213:50010, st
orageID=DS-393702405-10.0.30.213-50010-1222839388069, infoPort=50075, ipcPort=50020):Got exception while serving blk_-2928881016196368948_207241 to /10.0.30.213:
hadoop-zvents-datanode-motherlode010.admin.zvents.com.log:java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write.
 ch : java.nio.channels.SocketChannel[connected local=/10.0.30.213:50010 remote=/10.0.30.213:60803]

}}}