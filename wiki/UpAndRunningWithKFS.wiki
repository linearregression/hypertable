#summary Instructions on how to get Hypertable up and running with KFS

==Starting the Servers==

*Step 1.* Pull the latest KFS source code and build it
{{{
cd ~/src/
svn co https://kosmosfs.svn.sourceforge.net/svnroot/kosmosfs/trunk kosmosfs 
cd kosmosfs/
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo ~/src/kosmosfs
make
make install
}}}

*Step 2.* Edit ~/src/kosmosfs/scripts/machines.cfg

*Step 3.* Kill the servers
{{{
cd ~/src/kosmosfs/scripts
python kfslaunch.py -f machines.cfg -S
}}}

*Step 4.* Upgrade the binaries

{{{
cd ~/src/kosmosfs/scripts
python kfssetup.py -f machines.cfg -b ../build/bin -u
}}}

*Step 5.* Launch the KFS servers
{{{
cd ~/src/kosmosfs/scripts
python kfslaunch.py -f machines.cfg -s
}}}

*Step 6.* Configure Capistrano for your specific cluster and KFS.  See DeployingHypertable for details.  The following is an example of how the variables at the top of the Capfile might be changed for KFS.
{{{
------------- Capfile ----------------
set :source_machine, "motherlode000"
set :install_dir,  "/data1/doug/hypertable" 
set :hypertable_version, "0.9.0.8"
set :dfs, "hadoop"
set :default_config, "/home/doug/conf/cluster1-standard.cfg"

role :master, "motherlode001"
role :slave,  "motherlode001", "motherlode002", "motherlode003", "motherlode004", "motherlode005", "motherlode006", "motherlode007", "motherlode008"
}}}

*Step 7.* Compile the Hypertable code and install under the installation directory (e.g. /data1/doug/hypertable)

*Step 8.* Distribute the installation
{{{
$ cap dist
}}}

*Step 9.* Start the servers
{{{
$ cap start
}}}

Now you sould be able to run the `~/hypertable/bin/hypertable` HQL command interpreter and start playing around.

==Stopping the System==

{{{
$ cap stop
}}}