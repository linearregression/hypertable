#summary Instructions on how to get Hypertable up and running with KFS

==Starting the Servers==

*Step 1.* Synchronize clocks on all machines

The system cannot operate correctly unless the clocks on all machines are synchronized.  Use the [http://www.ntp.org/ Network Time Protocol (ntp)] to ensure that the clocks get synchronized and remain in sync.  Run the 'date' command on all machines to make sure they are in sync.  The following Capistrano shell session show the output of a cluster with properly synchronized clocks.

{{{
cap> date
[establishing connection(s) to motherlode000, motherlode001, motherlode002, motherlode003, motherlode004, motherlode005, motherlode006, motherlode007, motherlode008]
 ** [out :: motherlode001] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode002] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode003] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode004] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode005] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode007] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode006] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode000] Sat Jan  3 18:05:33 PST 2009
 ** [out :: motherlode008] Sat Jan  3 18:05:33 PST 2009
}}}

*Step 1.* Pull the latest KFS source code and build it
{{{
cd ~/src/
svn co https://kosmosfs.svn.sourceforge.net/svnroot/kosmosfs/trunk kosmosfs 
cd kosmosfs/
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo ~/src/kosmosfs
make
make install
}}}

*Step 2.* Edit [http://www.hypertable.org/doc/kfs-machines.cfg ~/src/kosmosfs/scripts/machines.cfg]

*Step 3.* Kill the servers
{{{
cd ~/src/kosmosfs/scripts
python kfslaunch.py -f machines.cfg -S
}}}

*Step 4.* Upgrade the binaries

{{{
cd ~/src/kosmosfs/scripts
python kfssetup.py -f machines.cfg -b /opt/kfs -u
}}}

*Step 5.* Launch the KFS servers
{{{
cd ~/src/kosmosfs/scripts
python kfslaunch.py -f machines.cfg -s
}}}

*Step 6.* Make sure the servers are up
{{{
cd /opt/kfs/bin/tools
./kfsping -m -s motherlode001 -p 20000
}}}

*Step 7.* Configure Capistrano for your specific cluster and KFS.  See [DeployingHypertable How to Deploy Hypertable] for details.  The following is an example of how the variables at the top of the Capfile might be changed for KFS.
{{{
------------- Capfile ----------------
set :source_machine, "motherlode000"
set :install_dir,  "/data1/doug/hypertable" 
set :hypertable_version, "0.9.0.10"
set :default_config, "/home/doug/conf/cluster1-standard.cfg"

role :master, "motherlode001"
role :slave,  "motherlode001", "motherlode002", "motherlode003", "motherlode004", "motherlode005", "motherlode006", "motherlode007", "motherlode008"
}}}

*Step 8.* Compile the Hypertable code and install under the installation directory (e.g. /data1/doug/hypertable)

*Step 9.* Distribute the installation
{{{
$ cap dist
}}}

*Step 10.* Start the servers
{{{
$ cap -S dfs=kfs start
}}}

Now you sould be able to run the `~/hypertable/bin/hypertable` HQL command interpreter and start playing around.

==Stopping the System==

{{{
$ cap -S dfs=kfs stop
}}}