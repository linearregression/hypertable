#summary A proposal for an implementation of a query cache

=== Point of Interception ===
For cache population and exploitation, the natural interception point seems to be the !RangeServer::create_scanner() method, which is where !FillScanBlock returns a buffer with the data resulting from the query, given a !TableIdentifier, a !RangeSpec and a !ScanSpec.

For cache invalidation, the best interception point seems to be the !RangeServer::update() method, which takes a !TableIdentifier and a buffer containing the affected keys and the new data associated to them.

=== Cache Key ===
Ideally the key to the cache would be the !TableIdentifier and the row keys that are contained in the buffer resulting from resolving the query. Since that can't be obtained without actually resolving the query, the next best thing would be to calculate the intersection of the !RangeSpec (which refers to a range being served by the !RangeServer for the specified table) and the !ScanSpec (which represents the WHERE clause in the HQL query). But since that intersection is also only known after obtaining the result of the query, it also can't be used as a key to the query.

So we propose using the !TableIdentifier and the !ScanSpec as the cache key. To that end, a !TableScanSpec class is defined, which combines the two components and provides the appropriate comparators.

=== Cache Invalidation ===
Whenever a key contained in a range held by the cache is updated, that range needs to be invalidated, meaning that it will be deleted from the cache.

Since the cache keys do not contain specific row keys but ranges of them, some way to obtain the ranges affected by each updated row key has to be devised.

The simplest way to identify the ranges affected by one row key is to walk through the list of N cached ranges and determine, for each one, if the row key falls into it. As this needs to be repeated for each or the M updated row key, this results in N*M operations (this is further complicated by the fact that each range can contain sub-ranges, but these are expected to be few and therefore need no special optimization).

One way to optimize this process could be to index the cached ranges both by starting row key and by ending row key. Also, the mean key value K should be calculated. With this, the way to determine which ranges are affected by a given updated row key is as follows:

  * If the updated row key is less or equal than K, access the index for starting row keys and iterate it downward.
  * If the updated row key is greater than K, access the index for ending row keys and iterate it upwards.
  * For each resulting range, iterate its sub-ranges to determine if any of them contain the updated row key.
 
This should result in a mean of N*M/4 ops and a worst case of N*M ops (when all ranges are the same), which is not ideal (we'd rather see a log() in there), but it is an improvement nonetheless.